
This codebase is designed for our multilingual paper: including language-aware layer normalization and
language-aware linear mapping. Improving language-specific modeling help enhance the model capacity on
different translation directions so as to deliver better translation performance.

Deepening neural models also help a lot. We applied the depth-scaled initialization to alleviate gradient
vanishing and got decent performance gains.

The source code and scripts might contain bugs. For any issues, please contact [Biao Zhang](B.Zhang@ed.ac.uk).